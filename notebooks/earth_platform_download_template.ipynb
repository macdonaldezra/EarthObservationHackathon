{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Sentinel-2 Data from EarthDaily Analytics' Earth Platform\n",
        "\n",
        "This notebook provides a guide for downloading [Sentinel-2](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2) data from the [EarthDaily Analytics Earth Platform](https://earthplatform.eds.earthdaily.com/) and displaying some of the data downloaded from this platform.\n",
        "\n",
        "Ideally, this is a template for downloading Sentinel-2 data for an area **you** are interested in learning more about and inspiring **you** to perform your own analysis based on your own personal whimsy.\n",
        "\n",
        "We start by introducing techniques for querying the Platform by using a GeoJSON Polygon created for the Lower Mainland; recommend how you can go about creating your own; and then proceed with an example for querying and displaying data from this store.\n",
        "\n",
        "### What you Need to Run this Notebook:\n",
        "\n",
        "(1) A file located in the same directory as this notebook called `.env` containing the following format and values:\n",
        "\n",
        "```bash\n",
        "CLIENT_ID=\"very_real_client_id_for_earthdaily_analytics_platform\"\n",
        "CLIENT_SECRET=\"very_real_client_secret_for_earthdaily_analytics_platform\"\n",
        "AUTH_TOKEN_URL=\"very_real_url_for_connecting_to_earthdaily_platform\"\n",
        "API_URL=\"very_real_api_url_for_reaching_earthdaily_dataset\"\n",
        "```\n",
        "\n",
        "These values should be provided to you, but if you do not have them, please ask someone in the know.\n",
        "\n",
        "(2) jazz hands?\n",
        "\n",
        "Now that we have that squared away we are going to start by installing some required Python packages for this notebook."
      ],
      "metadata": {
        "id": "ENSXmL8J0VW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install folium fsspec geopandas mapclassify python-dotenv pystac-client shapely"
      ],
      "metadata": {
        "id": "yjBuXOvD0Zf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from pystac_client import Client\n",
        "from pystac.item import Item\n",
        "from shapely.geometry import shape\n",
        "\n",
        "import cv2\n",
        "import folium\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tifffile as tiff"
      ],
      "metadata": {
        "id": "wKk8DvgB2Ot7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Areas of Interest\n",
        "\n",
        "To start, we need to create an area of interest that we want to analyze further.\n",
        "\n",
        "If you have an area in mind already that you want to explore and learn more about, you can create your own GeoJSON file at [geojson.io](https://geojson.io/) or using an open source service like [QGIS](https://qgis.org/en/site/).\n",
        "\n",
        "You can also download pre-built Shapefiles from services like [OpenStreetMap](https://download.geofabrik.de/) or from some of the resources mentioned in [this post by Carleton University](https://library.carleton.ca/find/gis/geospatial-data/shapefiles-canada-united-states-and-world).\n",
        "\n",
        "We are going to start with a GeoJSON polygon that I've pre-built using geojson.io's interface that covers the some of Vancouver, BC, Canada and will inspect some Sentinel-2 tiles from the EarthDaily platform."
      ],
      "metadata": {
        "id": "7NTsmgXn3-9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example GeoJSON geometry\n",
        "geojson_geometry = {\n",
        "    # I drew a Polygon at geojson.io and put the contents of the `geometry` attribute here\n",
        "    \"type\": \"Polygon\",\n",
        "    \"coordinates\": [\n",
        "        [\n",
        "            [-123.19443904574592, 49.24932487550103],\n",
        "            [-123.17802762978633, 49.13635374192958],\n",
        "            [-123.03251301430745, 49.04966338761224],\n",
        "            [-122.73054282797881, 49.06113525720673],\n",
        "            [-122.68349674929038, 49.13420622071877],\n",
        "            [-122.77868300152072, 49.255752174748864],\n",
        "            [-122.98984330819309, 49.29073056863652],\n",
        "            [-123.19443904574592, 49.24932487550103],\n",
        "        ]\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Convert the GeoJSON geometry into a shapely geometry\n",
        "shapely_geometry = shape(geojson_geometry)\n",
        "\n",
        "# Please Note: You can also create, download, or import your own Shapefile to use with GeoPandas\n",
        "# and create a GeoDataFrame from it. To do this see the docs at:\n",
        "# https://geopandas.org/en/stable/docs/user_guide/io.html#reading-spatial-data\n",
        "# and take a look at the geopandas read_file method.\n",
        "\n",
        "# Create a GeoDataFrame with the shapely geometry\n",
        "# Note that the Coordinate Reference System (CRS) defines how the two-dimensional,\n",
        "# projected geometry relates to real world locations.\n",
        "gdf = gpd.GeoDataFrame([{\"geometry\": shapely_geometry}], crs=\"EPSG:4326\")\n",
        "\n",
        "# Calculate the centroid of your GeoDataFrame to center the map\n",
        "centroid = gdf.geometry.centroid.unary_union.centroid\n",
        "\n",
        "# Create a folium map centered on the centroid of your shapefile\n",
        "m = folium.Map(location=[centroid.y, centroid.x], zoom_start=10)\n",
        "\n",
        "# Add the GeoDataFrame as a layer to the folium map\n",
        "folium.GeoJson(gdf, name=\"geojson\").add_to(m)\n",
        "\n",
        "# Add layer control to toggle the geojson layer\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "# Display the map\n",
        "m"
      ],
      "metadata": {
        "id": "aM5GRUEc3704"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Data\n",
        "\n",
        "To download Sentinel-2 data from the Earth Platform we are going to use the [SpatioTemporal Asset Catalog (STAC)](https://stacspec.org/en) interface - a common language used to describe geospatial information. To do this, we need to authenticate with this platform using our precious credentials and then we can use the GeoDataFrame object we've already created to download data from the platform.\n",
        "\n",
        "We demonstrate how to authorization token from this service in the following cell."
      ],
      "metadata": {
        "id": "9ydyO8WX44T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv(\n",
        "    # You will need to create this file with your\n",
        "    # CLIENT_ID, CLIENT_SECRET, AUTH_TOKEN_URL, and API_URL\n",
        "    dotenv_path=\"secrets.env\"\n",
        ")\n",
        "\n",
        "CLIENT_ID = os.environ.get(\"CLIENT_ID\")\n",
        "CLIENT_SECRET = os.environ.get(\"CLIENT_SECRET\")\n",
        "AUTH_TOKEN_URL = os.environ.get(\"AUTH_TOKEN_URL\")\n",
        "API_URL = os.environ.get(\"API_URL\")\n",
        "\n",
        "\n",
        "def get_new_token(client_id: str, client_secret: str, auth_token_url: str):\n",
        "    \"\"\"\n",
        "    Authenticate with the Earth Platform and obtain a new access token.\n",
        "    \"\"\"\n",
        "    token_req_payload = {\"grant_type\": \"client_credentials\"}\n",
        "    token_response = requests.post(\n",
        "        auth_token_url,\n",
        "        data=token_req_payload,\n",
        "        allow_redirects=False,\n",
        "        auth=(client_id, client_secret),\n",
        "    )\n",
        "    token_response.raise_for_status()  # Raise an exception if the request failed\n",
        "\n",
        "    tokens = json.loads(token_response.text)\n",
        "    return tokens[\"access_token\"]\n",
        "\n",
        "\n",
        "token = get_new_token(CLIENT_ID, CLIENT_SECRET, AUTH_TOKEN_URL)\n",
        "# Open a client to the STAC API\n",
        "client = Client.open(API_URL, headers={\"Authorization\": f\"Bearer {token}\"})"
      ],
      "metadata": {
        "id": "TlilKDTo5XlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the STAC API\n",
        "\n",
        "Now that we have established a connection to the client, we can use the geometry we've selected and obtain Sentinel-2 tiles for that area of interest. We are going to start by returning the available items for our area of interest within our query constraints and will then decide which tiles we want to download for further use."
      ],
      "metadata": {
        "id": "wFELvXwD5dDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentinel2_data(\n",
        "    client: Client,\n",
        "    aoi: dict,\n",
        "    start_date: str,\n",
        "    end_date: str,\n",
        "    cloud_cover: float = 1,\n",
        "    max_items: int = 500,\n",
        "):\n",
        "    \"\"\"\n",
        "    Download Sentinel-2 data from the Earth Platform.\n",
        "    \"\"\"\n",
        "    query = client.search(\n",
        "        collections=[\"sentinel-2-l2a\"],\n",
        "        datetime=f\"{start_date}T00:00:00.000000Z/{end_date}T00:00:00.000000Z\",  # 2023-07-10T00:00:00.000000Z/2023-07-20T00:00:00.000000Z\n",
        "        intersects=aoi,  # The area of interest; you can also query by bbox, or other geometry\n",
        "        query={\"eo:cloud_cover\": {\"lte\": cloud_cover}},\n",
        "        sortby=[\n",
        "            {\n",
        "                \"field\": \"properties.eo:cloud_cover\",\n",
        "                \"direction\": \"asc\",\n",
        "            },  # Sort by cloud cover from lowest to highest\n",
        "        ],\n",
        "        limit=max_items,  # This is the number of items to be returned per page\n",
        "        max_items=max_items,  # This is number of items to page over\n",
        "    )\n",
        "\n",
        "    items = list(query.items())\n",
        "    if len(items) == 0:\n",
        "        raise Exception(\n",
        "            \"No items found, try enlarging search area or increasing cloud cover threshold.\"\n",
        "        )\n",
        "    print(f\"Found: {len(items):d} tiles.\")\n",
        "\n",
        "    # Convert STAC items into a GeoJSON FeatureCollection\n",
        "    stac_json = query.item_collection_as_dict()\n",
        "    gdf = gpd.GeoDataFrame.from_features(stac_json, crs=\"EPSG:4326\")\n",
        "\n",
        "    return items, gdf\n",
        "\n",
        "\n",
        "start_date = \"2023-06-01\"  # June 1, 2023\n",
        "end_date = \"2023-08-15\"  # August 15, 2023\n",
        "\n",
        "sentinel_items, sentinel_gdf = get_sentinel2_data(\n",
        "    client,\n",
        "    shapely_geometry,\n",
        "    start_date,\n",
        "    end_date,\n",
        "    cloud_cover=10,\n",
        "    max_items=50,\n",
        ")\n",
        "print(f\"Found {len(sentinel_items)} Sentinel-2 items/tiles.\")"
      ],
      "metadata": {
        "id": "-h57vWfb5nh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the tiles found for the given query on the map\n",
        "sentinel_gdf.explore(color=\"green\")"
      ],
      "metadata": {
        "id": "10YDKSyF5ti_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The items object contains a list of STAC items which includes\n",
        "# metadata about the satellite imagery and links to the actual data.\n",
        "# You can access the first item in the list like this:\n",
        "sentinel_items[0]"
      ],
      "metadata": {
        "id": "KbevAJ6q5vi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download our tiles\n",
        "\n",
        "Now we want to download our Sentinel-2 tiles from EarthDaily's Earth Store. In this example we are going to download all of the high, medium, and low resolution bands that are captured by the Sentinel-2 satellites. To learn a bit more about the significance of each captured band we are downloading, see this tutorial [here](https://gisgeography.com/sentinel-2-bands-combinations/).\n",
        "\n",
        "Note that the information we download in the below cells does not exhaust the available data for each tile. You can find links to different files like class labels and metadata on the tile by downloading more files found for a given Sentinel-2 item."
      ],
      "metadata": {
        "id": "cDa7Zkc76Bp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell creates utility functions to download the files associated with a STAC item to a local\n",
        "# file system.\n",
        "\n",
        "def download_file(href: str, outpath: Path):\n",
        "    \"\"\"\n",
        "    Given a URL, download the file to the specified path.\n",
        "    \"\"\"\n",
        "    with requests.get(href, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(outpath, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "\n",
        "def download_files_for_item(\n",
        "    item: Item, asset_dict: dict[str, str], outpath: Path, debug: bool = True\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Save all files of interest for a given item.\n",
        "\n",
        "    If one file fails to download return False, otherwise return True.\n",
        "    \"\"\"\n",
        "    if not outpath.exists():\n",
        "        outpath.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    for key, value in asset_dict.items():\n",
        "        if debug:\n",
        "          print(f\"Downloading {key} and relabeling to {value}\")\n",
        "        if key in item.assets:\n",
        "            if key in [\"tileinfo_metadata\"]:\n",
        "                file_outpath = outpath / f\"{value}.json\"\n",
        "            else:\n",
        "                file_outpath = outpath / f\"{value}.tiff\"\n",
        "            if not file_outpath.exists():\n",
        "                try:\n",
        "                    download_file(item.assets[key].href, file_outpath)\n",
        "                except requests.ConnectionError:\n",
        "                    print(\n",
        "                        f\"Failed to download {item.assets[key].href} for item {item.id}\"\n",
        "                    )\n",
        "                    return False\n",
        "                except requests.exceptions.ReadTimeout:\n",
        "                    print(\n",
        "                        f\"Experienced a read timeout for {item.assets[key].href} for item {item.id}\"\n",
        "                    )\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"Skipping {item.assets[key].href} as it already exists.\")\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "aWr0cgt_5_HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_resolution_bands = {\"red\": \"B04\", \"green\": \"B03\", \"blue\": \"B02\", \"nir\": \"B08\"}\n",
        "mid_resolution_bands = {\n",
        "    \"rededge1\": \"B05\",\n",
        "    \"rededge2\": \"B06\",\n",
        "    \"rededge3\": \"B07\",\n",
        "    \"nir08\": \"B8A\",\n",
        "    \"swir16\": \"B11\",\n",
        "    \"swir22\": \"B12\",\n",
        "}\n",
        "low_resolution_bands = {\"coastal\": \"B01\", \"nir09\": \"B09\"}\n",
        "other_files = {\n",
        "    \"scl\": \"scl\",  # Scene Classification Map\n",
        "    \"tileinfo_metadata\": \"metadata\",  # Tile Metadata\n",
        "}\n",
        "all_download_files = { # Modify this variable to change the files that are downloaded\n",
        "    **high_resolution_bands,\n",
        "    **mid_resolution_bands,\n",
        "    **low_resolution_bands,\n",
        "    **other_files,\n",
        "}\n",
        "\n",
        "\n",
        "def download_and_tile_files(items: list[Item], download_files: dict[str, str], output_dir: Path):\n",
        "    \"\"\"\n",
        "    Given a GeoDataFrame of items and a list of STAC items, download the\n",
        "    files to a given output directory.\n",
        "\n",
        "    Parameters:\n",
        "      items: A list of items that correspond to tiles found in the GeoDataFrame and include paths to files to be\n",
        "        downloaded in this function.\n",
        "      download_files: A dictionary of strings where the keys correspond to names of items on the Earth Platform\n",
        "        and the values correspond to their Sentinel-2 name.\n",
        "    \"\"\"\n",
        "    downloaded = 0\n",
        "    for index, tile in enumerate(items):\n",
        "        dt_obj = datetime.strptime(tile.properties[\"datetime\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "        formatted_date = dt_obj.strftime(\"%Y%m%d\")\n",
        "        out_path = output_dir / tile.id / formatted_date\n",
        "        downloaded = download_files_for_item(tile, download_files, out_path)\n",
        "\n",
        "        if downloaded:\n",
        "            downloaded += 1\n",
        "        else:\n",
        "            print(f\"Unable to download file for item with id: {tile.id} at index: {index} in items list.\")\n",
        "\n",
        "    print(\n",
        "        f\"Downloaded all bands for {downloaded} tiles. Failed to download at least one \"\n",
        "        + f\"band or file for {len(items) - downloaded} tiles.\"\n",
        "    )\n",
        "\n",
        "\n",
        "output_dir = Path(\"/content/sentinel_tiles\") # Used for Google CoLab\n",
        "\n",
        "# We are only going to download 2 tiles here, but feel free to modify this function\n",
        "# call to download more data!\n",
        "download_and_tile_files(sentinel_items[0:2], all_download_files, output_dir)"
      ],
      "metadata": {
        "id": "MSA7uVlJ6Et9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis\n",
        "\n",
        "Now that we have downloaded atmospherically corrected Sentinel-2 data, we are going to display some common representations of the images that with any luck will serve as inspiration for doing something fancy."
      ],
      "metadata": {
        "id": "1hHuzF2w7mcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(image_dict):\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    for i, (title, image) in enumerate(image_dict.items()):\n",
        "        row = i // 3\n",
        "        col = i % 3\n",
        "        axes[row, col].imshow(image)\n",
        "        axes[row, col].set_title(title)\n",
        "        axes[row, col].axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def crop_center_square(arr, max_dim: int = 1000):\n",
        "    \"\"\"\n",
        "    Selects up to the center max_pixels from an nxnxc input array, or n pixels if 1000 > n,\n",
        "    where c is the number of channels (e.g., 3 for an RGB image).\n",
        "\n",
        "    Parameters:\n",
        "        arr (np.ndarray): The input array from which to select pixels, with shape (n, n, c).\n",
        "        max_pixels (int): The maximum number of pixels to select if possible (default is 1000).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The selected portion of the input array, maintaining the channel dimension.\n",
        "    \"\"\"\n",
        "    if arr.ndim > 3 or arr.ndim < 2:\n",
        "        raise ValueError(\n",
        "            \"Unable to crop center of array with number of dimensions:\"\n",
        "            + f\" {arr.ndim}, must have only 2 or 3 dimensions.\"\n",
        "        )\n",
        "    if max_dim > arr.shape[0]:\n",
        "        return arr\n",
        "\n",
        "    # Calculate starting indices to select the square from the center\n",
        "    start_index = (arr.shape[0] - max_dim) // 2\n",
        "\n",
        "    # Select the square, preserving the channel dimension\n",
        "    if arr.ndim == 3:\n",
        "        selected_square = arr[start_index:start_index + max_dim, start_index:start_index + max_dim, :]\n",
        "    elif arr.ndim == 2:\n",
        "        selected_square = arr[start_index:start_index + max_dim, start_index:start_index + max_dim]\n",
        "\n",
        "\n",
        "    return selected_square\n",
        "\n",
        "\n",
        "def scale_band(\n",
        "    band: np.ndarray, percentile: float = 95, max_reflectance: bool = True\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Scale the band to 0-1.\n",
        "\n",
        "    max_reflectance: If True, the band is scaled to 0-1 by dividing by 10000.\n",
        "      If False, the band is scaled to 0-1 by dividing by the percentile.\n",
        "    \"\"\"\n",
        "    if max_reflectance:\n",
        "        return np.clip(band / 10000, 0, 1)\n",
        "    else:\n",
        "        return band / np.percentile(band, percentile)\n",
        "\n",
        "\n",
        "def display_transformed_images(data_path: Path, percentile: int = 95, num_pixels: int = 1500):\n",
        "    \"\"\"\n",
        "    Generate Sentinel-2 images from the given filepath. The returned images are as follows:\n",
        "       NDVI: Normalized Difference Vegetation Index\n",
        "       NDBI: Normalized Difference Built-up Index\n",
        "       NDWI: Normalized Difference Water Index\n",
        "       False Color: B08, B04, B03\n",
        "       Mask: The class labels for each pixel\n",
        "\n",
        "    Please Note: If the size of the input\n",
        "\n",
        "    Note: If the input tile contains 0 values (ie. black squares in the tiles),\n",
        "      a warning will be printed due to division by zero.\n",
        "    \"\"\"\n",
        "    # Unpack the bands\n",
        "    B02 = crop_center_square(\n",
        "        scale_band(\n",
        "            tiff.imread(f\"{data_path}/B02.tiff\"),\n",
        "            percentile=percentile,\n",
        "        ),\n",
        "        num_pixels\n",
        "    )\n",
        "    B03 = crop_center_square(\n",
        "        scale_band(\n",
        "            tiff.imread(f\"{data_path}/B03.tiff\"),\n",
        "            percentile=percentile,\n",
        "        ),\n",
        "        num_pixels\n",
        "    )\n",
        "    B04 = crop_center_square(\n",
        "        scale_band(\n",
        "            tiff.imread(f\"{data_path}/B04.tiff\"),\n",
        "            percentile=percentile,\n",
        "        ),\n",
        "        num_pixels\n",
        "    )\n",
        "    B08 = crop_center_square(\n",
        "        scale_band(\n",
        "            tiff.imread(f\"{data_path}/B08.tiff\"),\n",
        "            percentile=percentile,\n",
        "        ),\n",
        "        num_pixels\n",
        "    )\n",
        "    B11 = crop_center_square(\n",
        "        scale_band(\n",
        "            cv2.resize(\n",
        "                tiff.imread(f\"{data_path}/B11.tiff\"),\n",
        "                None,\n",
        "                fx=2,\n",
        "                fy=2,\n",
        "                interpolation=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            percentile=percentile,\n",
        "        ),\n",
        "        num_pixels\n",
        "    )\n",
        "    B12 = crop_center_square(\n",
        "        scale_band(\n",
        "            cv2.resize(\n",
        "                tiff.imread(f\"{data_path}/B12.tiff\"),\n",
        "                None,\n",
        "                fx=2,\n",
        "                fy=2,\n",
        "                interpolation=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            percentile=percentile,\n",
        "        ),\n",
        "        num_pixels\n",
        "    )\n",
        "\n",
        "    # Calculate NDVI (Normalized Difference Vegetation Index)\n",
        "    NDVI = (B08 - B04) / (B08 + B04)\n",
        "\n",
        "    # # Calculate NDBI (Normalized Difference Built-Up Index)\n",
        "    NDBI = (B11 - B08) / (B11 + B08)\n",
        "\n",
        "    # Calculate NDWI (Normalized Difference Water Index)\n",
        "    NDWI = (B08 - B12) / (B08 + B12)\n",
        "\n",
        "    # Calculate NBR (Normalized Burn Ratio)\n",
        "    NBR = (B08 - B12) / (B08 + B12)\n",
        "\n",
        "    # Create a color image using RGB bands\n",
        "    RGB = np.stack([B04, B03, B02], axis=-1)\n",
        "\n",
        "    # Create a false-color composite image\n",
        "    false_color = np.stack([B08, B04, B03], axis=-1)\n",
        "    images = {\n",
        "        \"NDVI\": NDVI,\n",
        "        \"NDBI\": NDBI,\n",
        "        \"NDWI\": NDWI,\n",
        "        \"NBR\": NBR,\n",
        "        \"RGB\": RGB,\n",
        "        \"False Color\": false_color,\n",
        "    }\n",
        "\n",
        "    display_images(images)\n",
        "\n",
        "    return images\n",
        "\n",
        "# Note: Please update data_path based on the root directory of one tile\n",
        "data_path = Path(\n",
        "    \"/content/sentinel_tiles/S2A_10UDV_20230607_0_L2A/20230607\"\n",
        ")\n",
        "display_pixels = 2000 # Number of center pixels to display for image\n",
        "\n",
        "images = display_transformed_images(data_path, num_pixels=display_pixels)"
      ],
      "metadata": {
        "id": "F040qrqaCFrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Scene Classification Map\n",
        "\n",
        "While applying atmospheric corrections to Sentinel-2 data the Level-2A Algorithm also generates a map that classifies pixels based on the captured data for that pixel. More information on this algorithm can be found [here](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm-overview).\n",
        "\n",
        "In the below cell we display the scene classification map for the obtain image and the corresponding class names."
      ],
      "metadata": {
        "id": "9gtLQ7vB1Ml0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "SCENE_CLASSES = { # Source: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/scene-classification/\n",
        "    0: [0, 0, 0],        # No Data (Missing data) - black\n",
        "    1: [255, 0, 0],      # Saturated or defective pixel - red\n",
        "    2: [47, 47, 47],     # Topographic casted shadows - very dark grey\n",
        "    3: [100, 50, 0],     # Cloud shadows - dark brown\n",
        "    4: [0, 160, 0],      # Vegetation - green\n",
        "    5: [255, 230, 90],   # Not-vegetated - dark yellow\n",
        "    6: [0, 0, 255],      # Water (dark and bright) - blue\n",
        "    7: [128, 128, 128],  # Unclassified - dark grey\n",
        "    8: [192, 192, 192],  # Cloud medium probability - grey\n",
        "    9: [255, 255, 255],  # Cloud high probability - white\n",
        "    10: [100, 200, 255], # Thin cirrus - very bright blue\n",
        "    11: [255, 150, 255], # Snow or ice - very bright pink\n",
        "}\n",
        "LABEL_NAMES = {\n",
        "    0: \"No Data (Missing data)\",\n",
        "    1: \"Saturated or defective pixel\",\n",
        "    2: \"Topographic casted shadows\",\n",
        "    3: \"Cloud shadows\",\n",
        "    4: \"Vegetation\",\n",
        "    5: \"Not-vegetated\",\n",
        "    6: \"Water (dark and bright)\",\n",
        "    7: \"Unclassified\",\n",
        "    8: \"Cloud medium probability\",\n",
        "    9: \"Cloud high probability\",\n",
        "    10: \"Thin cirrus\",\n",
        "    11: \"Snow or ice\",\n",
        "}\n",
        "\n",
        "\n",
        "def get_scene_classification_map(data_path: Path, class_map: dict[int, list[int]] = SCENE_CLASSES):\n",
        "    \"\"\"\n",
        "    Read in the Scene Classification Map downloaded from EarthDaily and return\n",
        "    colorized array.\n",
        "    \"\"\"\n",
        "    scl = tiff.imread(data_path)\n",
        "    color_image = np.array([SCENE_CLASSES[value] for row in scl for value in row])\n",
        "    color_image = color_image.reshape(*scl.shape, 3)\n",
        "\n",
        "    return color_image\n",
        "\n",
        "\n",
        "def display_scl_map(scl: np.ndarray):\n",
        "    \"\"\"\n",
        "    Given the scene classification map and the predefined label names and legend\n",
        "    information, display the Scene Classification Map and the corresponding class\n",
        "    labels.\n",
        "    \"\"\"\n",
        "    patches = [mpatches.Patch(color=np.array(color)/255.0, label=LABEL_NAMES[i]) for i, color in SCENE_CLASSES.items()]\n",
        "\n",
        "    # Display the color image with legend\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.imshow(scl)\n",
        "    plt.axis('off')  # Hide the axis to emphasize the image\n",
        "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "scl = get_scene_classification_map(f\"{data_path}/scl.tiff\")\n",
        "display_scl_map(scl)"
      ],
      "metadata": {
        "id": "R6X4F6c_wZLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}